import asyncio
import logging
import os
from pathlib import Path
from typing import List, Optional, Dict, Any

from .voice_generator import VoiceGenerator
from .image_processor import ImageProcessor
from .sync_manager import SyncManager
from ..config_loader import ROOT_DIR

logger = logging.getLogger(__name__)

class VideoEngine:
    """
    Orchestrates the creation of synchronized video from text and images.
    Replaces external video generation services with local FFmpeg pipeline.
    """
    
    def __init__(self):
        self.voice_generator = VoiceGenerator()
        self.image_processor = ImageProcessor()
        self.sync_manager = SyncManager()
        
    async def create_video(
        self,
        script_text: str,
        image_paths: List[str],
        output_filename: str = "final_video.mp4",
        marker_words: Optional[List[str]] = None
    ) -> str:
        """
        Full pipeline: Voice -> Images -> Sync -> FFmpeg Assembly.
        
        Args:
            script_text: The text to be spoken.
            image_paths: List of absolute paths to input images.
            output_filename: Name of the output video file.
            marker_words: Optional list of words to trigger image changes.
            
        Returns:
            Path to the final MP4 video.
        """
        # Create a workspace directory for this job
        job_id = os.urandom(4).hex()
        work_dir = ROOT_DIR / "tests" / "data" / "artifacts" / f"job_{job_id}"
        work_dir.mkdir(parents=True, exist_ok=True)
        
        try:
            # 1. Voice & Timing Extraction
            logger.info("Step 1: Generating Voice & Timing...")
            audio_path, alignment_data = await self.voice_generator.generate_with_timestamps(
                text=script_text,
                output_path=str(work_dir / "speech.mp3")
            )
            
            # 2. Asset Standardizing (Pillow)
            logger.info("Step 2: Processing Images...")
            processed_images = self.image_processor.process_images(
                image_paths=image_paths,
                output_dir=str(work_dir)
            )
            
            # 3. The "Sync Map" Generation
            logger.info("Step 3: Generating Sync Maps...")
            inputs_txt_path = self.sync_manager.generate_sync_map(
                processed_images=processed_images,
                alignment_data=alignment_data,
                marker_words=marker_words,
                output_dir=str(work_dir)
            )
            
            subs_ass_path = self.sync_manager.generate_subtitles(
                alignment_data=alignment_data,
                output_dir=str(work_dir)
            )
            
            # 4. The Final Assembly (FFmpeg)
            logger.info("Step 4: Final Assembly with FFmpeg...")
            output_video_path = work_dir / output_filename
            
            await self._run_ffmpeg_assembly(
                inputs_txt=inputs_txt_path,
                audio_path=audio_path,
                subs_path=subs_ass_path,
                output_path=str(output_video_path)
            )
            
            logger.info(f"Video created successfully: {output_video_path}")
            return str(output_video_path)
            
        except Exception as e:
            logger.error(f"VideoEngine pipeline failed: {e}")
            raise

    async def _run_ffmpeg_assembly(
        self,
        inputs_txt: str,
        audio_path: str,
        subs_path: str,
        output_path: str
    ):
        """
        Executes the FFmpeg command to stitch everything together.
        """
        # FFmpeg command from user example:
        # ffmpeg -f concat -safe 0 -i inputs.txt \
        # -i speech.mp3 \
        # -vf "ass=subs.ass" \
        # -c:v libx264 -pix_fmt yuv420p -r 30 \
        # -c:a copy -shortest \
        # final_video.mp4
        
        # Note: We need absolute paths for concat file if safe 0 is used, or relative.
        # But 'inputs.txt' generated by SyncManager likely uses absolute paths if we passed absolute paths.
        # Let's check SyncManager. It writes whatever we pass in `processed_images`.
        # ImageProcessor returns absolute paths.
        
        cmd = [
            "ffmpeg",
            "-f", "concat",
            "-safe", "0",
            "-i", inputs_txt,
            "-i", audio_path,
            # CRITICAL FIX: Force frame rate conversion BEFORE subs.
            # Otherwise, concat demuxer passes a single long-duration frame, 
            # and the subtitle gets burnt into that one frame for the entire duration.
            "-vf", f"fps=30,ass={subs_path}", 
            "-c:v", "libx264",
            "-pix_fmt", "yuv420p",
            # "-r", "30", # -r is output option, already covered by fps filter effectively, but consistent to keep or remove. 
            # safe to keep for metadata
            "-r", "30",
            "-c:a", "copy",
            "-shortest",
            "-y", # overwrite
            output_path
        ]
        
        # Save the command for debugging
        cmd_str = " ".join(cmd)
        cmd_log_path = Path(output_path).parent / "ffmpeg_cmd.txt"
        with open(cmd_log_path, "w") as f:
            f.write(cmd_str)
            
        logger.info(f"Running FFmpeg: {cmd_str}")
        
        process = await asyncio.create_subprocess_exec(
            *cmd,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )
        
        stdout, stderr = await process.communicate()
        
        if process.returncode != 0:
            error_msg = stderr.decode().strip()
            logger.error(f"FFmpeg failed: {error_msg}")
            raise Exception(f"FFmpeg failed: {error_msg}")
            
        logger.debug(f"FFmpeg output: {stdout.decode()}")
